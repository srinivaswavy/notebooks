{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9759f399-9c8d-491f-99aa-cfcd39cb28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254ce2a2-f78f-4ae2-a818-b15d06639b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e686d8-b761-485a-9beb-42a075f100e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e165d8-862f-4592-ae9e-d97cfc6786fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Time taken for matrix multiplication: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create random tensors\n",
    "size = 10000 \n",
    "a = torch.randn(size, size, device=device)\n",
    "b = torch.randn(size, size, device=device)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(10):\n",
    "    c = torch.matmul(a, b)\n",
    "\n",
    "# Measure time\n",
    "start_time = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken for matrix multiplication: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3a5ee8-1d29-4501-8eb3-6c309894f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Time taken for multiple operations: 9.512589931488037 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create larger random tensors\n",
    "size = 20000\n",
    "a = torch.randn(size, size, device=device)\n",
    "b = torch.randn(size, size, device=device)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(10):\n",
    "    c = torch.matmul(a, b)\n",
    "\n",
    "# Measure time for multiple operations\n",
    "start_time = time.time()\n",
    "for _ in range(10):\n",
    "    c = torch.matmul(a, b)\n",
    "    c = torch.sin(c)\n",
    "    c = torch.exp(c)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken for multiple operations: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0cec97-c936-4083-a85c-230cc9fd6b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Time taken for 10 training steps: 0.00999307632446289 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Define a simple CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 1024)  # Adjusted to match the input size\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create random input tensor\n",
    "input_tensor = torch.randn(64, 3, 32, 32, device=device)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Warm-up\n",
    "model.train()\n",
    "for _ in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_tensor)\n",
    "    loss = criterion(outputs, torch.randint(0, 10, (64,), device=device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Measure time for training step\n",
    "start_time = time.time()\n",
    "for _ in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_tensor)\n",
    "    loss = criterion(outputs, torch.randint(0, 10, (64,), device=device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken for 10 training steps: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1f1e87-60c8-47ce-87ad-c0342c1aa1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create a tensor and print its device\n",
    "tensor = torch.randn(10, device=device)\n",
    "print(f\"Tensor is on device: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8acfa4-ccd6-4b12-86fa-49538faa04ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 10000 operations: 1.5645 seconds\n",
      "Average time per operation: 0.0002 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def test_gpu_performance(device='cuda'):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available. Please check your GPU setup.\")\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Define the size of the tensor and number of operations\n",
    "    tensor_size = (1024, 1024)  # Adjust size as needed\n",
    "    num_operations = 10000\n",
    "\n",
    "    # Generate random tensors and move them to GPU\n",
    "    a = torch.randn(tensor_size, device=device)\n",
    "    b = torch.randn(tensor_size, device=device)\n",
    "\n",
    "    # Warm-up GPU\n",
    "    for _ in range(10):\n",
    "        _ = a + b\n",
    "        _ = a @ b\n",
    "\n",
    "    # Measure performance\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for _ in range(num_operations):\n",
    "        c = a + b\n",
    "        d = a @ b\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_time_per_operation = elapsed_time / num_operations\n",
    "\n",
    "    print(f\"Elapsed time for {num_operations} operations: {elapsed_time:.4f} seconds\")\n",
    "    print(f\"Average time per operation: {average_time_per_operation:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_gpu_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7367c6b-9038-48f7-88c6-99125b40742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 50 operations: 0.0032 seconds\n",
      "Average time per operation: 0.0001 seconds\n",
      "Elapsed time for concurrent operations with 4 threads: 0.0078 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def test_gpu_performance(device='cuda'):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available. Please check your GPU setup.\")\n",
    "    \n",
    "    # Set the device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Define the size of the tensor and number of operations\n",
    "    tensor_size = (4096, 4096)  # Larger tensor size\n",
    "    num_operations = 50  # Number of operations to perform\n",
    "\n",
    "    # Generate random tensors and move them to GPU\n",
    "    a = torch.randn(tensor_size, device=device)\n",
    "    b = torch.randn(tensor_size, device=device)\n",
    "\n",
    "    # Warm-up GPU\n",
    "    for _ in range(10):\n",
    "        _ = a + b\n",
    "        _ = a @ b\n",
    "        _ = a * b\n",
    "        _ = a.sin()\n",
    "        _ = a.mean()\n",
    "\n",
    "    # Measure performance\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for _ in range(num_operations):\n",
    "        c = a + b\n",
    "        d = a @ b\n",
    "        e = a * b\n",
    "        f = a.sin()\n",
    "        g = a.mean()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_time_per_operation = elapsed_time / num_operations\n",
    "\n",
    "    print(f\"Elapsed time for {num_operations} operations: {elapsed_time:.4f} seconds\")\n",
    "    print(f\"Average time per operation: {average_time_per_operation:.4f} seconds\")\n",
    "\n",
    "    # Test with multiple concurrent operations\n",
    "    num_threads = 4  # Number of threads to simulate concurrent operations\n",
    "    start_time = time.time()\n",
    "\n",
    "    def concurrent_operations():\n",
    "        for _ in range(num_operations // num_threads):\n",
    "            _ = a + b\n",
    "            _ = a @ b\n",
    "            _ = a * b\n",
    "            _ = a.sin()\n",
    "            _ = a.mean()\n",
    "\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(concurrent_operations) for _ in range(num_threads)]\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "\n",
    "    end_time = time.time()\n",
    "    concurrent_elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Elapsed time for concurrent operations with {num_threads} threads: {concurrent_elapsed_time:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_gpu_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f4d44-13ec-4f6a-904a-10cef4669645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-threaded elapsed time for 100 operations: 2.9766 seconds\n",
      "Average time per operation: 0.0298 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def tensor_operations(a, b):\n",
    "    # Perform a series of complex tensor operations\n",
    "    c = a + b\n",
    "    d = a @ b\n",
    "    e = a * b\n",
    "    f = a.sin()\n",
    "    g = a.mean()\n",
    "    h = a.log()\n",
    "    i = torch.relu(a)\n",
    "    j = torch.matmul(a, b)\n",
    "    k = torch.einsum('ij,jk->ik', a, b)\n",
    "    return c, d, e, f, g, h, i, j, k\n",
    "\n",
    "def test_gpu_performance(device='cuda'):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available. Please check your GPU setup.\")\n",
    "    \n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Define tensor size and number of operations\n",
    "    tensor_size = (8192, 8192)  # Larger tensor size for more stress\n",
    "    num_operations = 100  # Number of operations to perform\n",
    "    num_threads = 8  # Number of concurrent threads\n",
    "\n",
    "    # Generate random tensors and move them to GPU\n",
    "    a = torch.randn(tensor_size, device=device)\n",
    "    b = torch.randn(tensor_size, device=device)\n",
    "\n",
    "    # Warm-up GPU\n",
    "    for _ in range(20):\n",
    "        tensor_operations(a, b)\n",
    "\n",
    "    # Measure performance for a single-threaded operation\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_operations):\n",
    "        tensor_operations(a, b)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_time_per_operation = elapsed_time / num_operations\n",
    "    print(f\"Single-threaded elapsed time for {num_operations} operations: {elapsed_time:.4f} seconds\")\n",
    "    print(f\"Average time per operation: {average_time_per_operation:.4f} seconds\")\n",
    "\n",
    "    # Measure performance for multi-threaded operation\n",
    "    def concurrent_tasks():\n",
    "        for _ in range(num_operations // num_threads):\n",
    "            tensor_operations(a, b)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(concurrent_tasks) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "    end_time = time.time()\n",
    "    concurrent_elapsed_time = end_time - start_time\n",
    "    print(f\"Multi-threaded elapsed time with {num_threads} threads: {concurrent_elapsed_time:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_gpu_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db9298-d727-4978-b54e-95d9a31fbd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
